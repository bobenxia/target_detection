{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "copyrighted-removal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Ipynb_importer\n",
    "from a_csp_darknet53  import *\n",
    "from b_yolov4_neck import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "collaborative-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import (Add, BatchNormalization, Concatenate,\n",
    "                                     Conv2D, LeakyReLU, MaxPooling2D,Reshape,\n",
    "                                     UpSampling2D, ZeroPadding2D)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from scipy.special import expit, softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-ensemble",
   "metadata": {},
   "source": [
    "**先验框**\n",
    "\n",
    "在Yolov1中，网络直接回归检测框的宽、高，这样效果有限。所以在Yolov2中，改为了回归基于先验框的变化值，这样网络的学习难度降低，整体精度提升不小。Yolov3沿用了Yolov2中关于先验框的技巧，并且**使用k-means对数据集中的标签框进行聚类**，得到类别中心点的9个框，作为先验框。\n",
    "\n",
    "在COCO数据集中（原始图片全部resize为416 × 416），九个框分别是 (10×13)，(16×30)，(33×23)，(30×61)，(62×45)，(59× 119)， (116 × 90)， (156 × 198)，(373 × 326) ，顺序为w × h。\n",
    "\n",
    "> 注：先验框只与检测框的w、h有关，与x、y无关。\n",
    "\n",
    "1. **检测框解码**\n",
    "\n",
    "有了先验框与输出特征图，就可以解码检测框 x，y，w，h。\n",
    "\n",
    "![[公式]](https://www.zhihu.com/equation?tex=b_x%3D%5Csigma+%28t_x%29+%2B+c_x+%5C%5C+b_y%3D%5Csigma+%28t_y%29+%2B+c_y+%5C%5C+b_w%3Dp_we%5E%7Bt_w%7D++%5C%5C+b_h%3Dp_he%5E%7Bt_h%7D+%5C%5C)\n",
    "\n",
    "\n",
    "这里记特征图的大小为 ![[公式]](https://www.zhihu.com/equation?tex=%28W%2C+H%29) （在文中是 ![[公式]](https://www.zhihu.com/equation?tex=%2813%2C+13%29) )，这样我们可以将边界框相对于整张图片的位置和大小计算出来、\n",
    "\n",
    "![[公式]](https://www.zhihu.com/equation?tex=%5C%5Cb_x+%3D+%28%5Csigma+%28t_x%29%2Bc_x%29%2FW)\n",
    "\n",
    "![[公式]](https://www.zhihu.com/equation?tex=%5C%5C+b_y+%3D+%28%5Csigma+%28t_y%29+%2B+c_y%29%2FH)\n",
    "\n",
    "如下图所示， ![[公式]](https://www.zhihu.com/equation?tex=%5Csigma%28t_x%29%2C+%5Csigma%28t_y%29) 是基于矩形框中心点左上角格点坐标的偏移量， ![[公式]](https://www.zhihu.com/equation?tex=%5Csigma) 是**激活函数**，论文中作者使用**sigmoid**。 ![[公式]](https://www.zhihu.com/equation?tex=p_w%2C+p_h) 是先验框的宽、高，通过上述公式，计算出实际预测框的宽高 ![[公式]](https://www.zhihu.com/equation?tex=%28b_w%2C+b_h%29) 。\n",
    "\n",
    "<img src=\"https://pic2.zhimg.com/80/v2-758b1df9132a9f4b4e0c7def735e9a11_1440w.jpg\" alt=\"img\" style=\"zoom:40%;\" />\n",
    "\n",
    "举个具体的例子，假设对于第二个特征图26 × 26 × 3 × 85中的第[5，4，2]维，上图中的 ![[公式]](https://www.zhihu.com/equation?tex=c_y) 为5， ![[公式]](https://www.zhihu.com/equation?tex=+c_x) 为4，第二个特征图对应的先验框为(30×61)，(62×45)，(59× 119)，prior_box的index为2，那么取最后一个59，119作为先验w、先验h。这样计算之后的 ![[公式]](https://www.zhihu.com/equation?tex=b_x%2Cb_y) 还需要乘以特征图二的采样率16，得到真实的检测框x，y。\n",
    "\n",
    "2. **检测置信度解码**\n",
    "\n",
    "物体的检测置信度，在Yolo设计中非常重要，关系到算法的检测正确率与召回率。\n",
    "\n",
    "置信度在输出85维中占固定一位，由sigmoid函数解码即可，解码之后数值区间在[0，1]中。\n",
    "\n",
    "3. **类别解码**\n",
    "\n",
    "   > https://zhuanlan.zhihu.com/p/42865896\n",
    "   >\n",
    "   > 物体之间的相互覆盖都是不能避免的。因此一个锚点的感受野肯定会包含两个甚至更多个不同物体的可能。如果使用softmax作为激活函数，意味着在一个锚点中的检测是互斥的，只有一个或者说少数点的置信度可以大于阈值。使用sigmoid分类器，最终各类别之间的互斥被取消。\n",
    "\n",
    "COCO数据集有80个类别，所以类别数在85维输出中占了80维，每一维独立代表一个类别的置信度。使用sigmoid激活函数替代了Yolov2中的softmax，**取消了类别之间的互斥，可以使网络更加灵活。**\n",
    "\n",
    "三个特征图一共可以解码出 13 × 13 × 3 + 26 × 26 × 3 + 52 × 52 × 3 = 10647 个box以及相应的类别、置信度。这10647个box，在训练和推理时，使用方法不一样：\n",
    "\n",
    "1. 训练时10647个box全部送入打标签函数，进行后一步的标签以及损失函数的计算。\n",
    "2. 推理时，选取一个置信度阈值，过滤掉低阈值box，再经过nms（非极大值抑制），就可以输出整个网络的预测结果了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "renewable-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_decode(prediction, anchors, num_classes, input_dims, scale_x_y=None, use_softmax=False):\n",
    "    \"\"\"Decode final layer features to bounding box parameters\n",
    "    \n",
    "    Args:\n",
    "        prediction: feature layers([batch_size, grid_size, grid_size, num_anchors*(num_classes+5)])\n",
    "    \"\"\"\n",
    "    num_anchors = len(anchors)\n",
    "    batch_size = np.shape(prediction)[0]\n",
    "    grid_size = np.shaoe(prediction)[1:3]\n",
    "    # check if stride on height & width are same\n",
    "    assert input_dims[0]//grid_size[0] == input_dims[1] // grid_size[1], 'model stride mismatch'\n",
    "    stride = input_dims[0] // grid_size[0]\n",
    "    \n",
    "    prediction = np.reshape(prediction,\n",
    "                           (batch_size, grid_size[0]*grid_size[1]*num_anchors, num_classes+5))\n",
    "    \n",
    "    # ----------------------------------------------------------------------------------------------------------\n",
    "    # generate x_y_offset grid map\n",
    "    grid_y = np.arange(grid_size[0])\n",
    "    grid_x = np.arange(grid_size[1])\n",
    "    x_offset, y_offset = np.meshgrid(grid_x, grid_y)\n",
    "    \n",
    "    x_offset = np.reshape(x_offset, (-1, 1))\n",
    "    y_offset = np.reshape(y_offset, (-1, 1))\n",
    "    \n",
    "    x_y_offset = np.concatenate((x_offset, y_offset), axis=1)\n",
    "    x_y_offset = np.tile(x_y_offset, (1, num_anchors)) # 扩充至三倍\n",
    "    x_y_offset = np.reshape(x_y_offset, (-1, 2))  # 整形成行数增加\n",
    "    x_y_offset = np.expand_dims(x_y_offset, 0)\n",
    "    \n",
    "    # ----------------------------------------------------------------------------------------------------------\n",
    "    anchors = np.tile(anchors, (grid_size[0] * grid_size[1], 1))\n",
    "    anchors = np.expand_dims(anchors, 0)\n",
    "    \n",
    "    # 检测框解码\n",
    "    if scale_x_y:\n",
    "        # Eliminate grid sensitivity trick involved in YOLOv4\n",
    "        # https://zhuanlan.zhihu.com/p/139724869\n",
    "        box_xy_tmp = expit(prediction[..., :2]) * scale_x_y - (scale_x_y - 1) / 2\n",
    "        box_xy = (box_xy_tmp + x_y_offset) / np.arange(grid_size)[::-1]\n",
    "    else:\n",
    "        box_xy = (expit(prediction[..., :2]) + x_y_offset) / np.array(grid_size)[::-1]\n",
    "    box_wh = (np.exp(prediction[..., 2:4]) * anchors) / np.array(input_dims)[::-1]\n",
    "    \n",
    "    # ----------------------------------------------------------------------------------------------------------\n",
    "    # sigmoid objectness scores 置信度解码\n",
    "    objectness = expit(prediction[..., 4])  # p_o (objectness score)\n",
    "    objectness = np.expand_dims(objectness, -1)  # To make the same number of values for axis 0 and 1\n",
    "    \n",
    "    # ----------------------------------------------------------------------------------------------------------\n",
    "    # class scores 类别解码\n",
    "    if use_softmax:\n",
    "        class_scores = softmax(prediction[..., 5:], axis=-1)\n",
    "    else:\n",
    "        class_scores = explit(prediction[..., 5:])\n",
    "    \n",
    "    # (batch_size, grid_size[0]*grid_size[1]*num_anchors, ...))\n",
    "    return np.concatenate([box_xy, box_wh, objectness, class_scores], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "informative-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_handle_predictions(predictions, image_shape, max_boxes=100, confidence=0.1, iou_threshold=0.4, use_cluster_nms=False, use_wbf=False):\n",
    "    # 假设predictions尺寸为 [16, 16*16*3, 85] = [16, 768, 85]\n",
    "    boxes = predictions[:, :, :4]  # [16, 768, 4]\n",
    "    box_confidences = np.expand_dims(predictions[:, :, 4], -1)  # [16, 768, 1]\n",
    "    box_class_probs = predictions[:, :, 5:]  # [16, 768, 80]\n",
    "    \n",
    "    # filter boxes with confidence threshold\n",
    "    box_scores = box_confidences * box_class_probs # [16, 768, 80]\n",
    "    box_classes = np.argmax(box_scores, axis=-1)  # [16, 768]\n",
    "    box_class_scores = np.max(box_scores, axis=-1)  # [16, 768]\n",
    "    pos = np.where(box_class_scores >= confidence)  # [2, number<16*768]\n",
    "    \n",
    "    # 通过位置得到大于置信度的框、类别和分数\n",
    "    boxes = boxes[pos]  # [number, 4]\n",
    "    classes = box_classes[pos]  # [number, ]\n",
    "    scores = box_class_scores[pos]  # [number, ]\n",
    "    \n",
    "    if use_cluster_nms:\n",
    "        # use Fast/Cluster NMS for boxes postprocess\n",
    "        n_boxes, n_classes, n_scores = fast_cluster_nms_boxes(boxes, classes, scores, iou_threshold, confidence=confidence)\n",
    "    elif use_wbf:\n",
    "        # use Weighted-Boxes-Fusion for boxes postprocess\n",
    "        n_boxes, n_classes, n_scores = weighted_boxes_fusion([boxes], [classes], [scores], image_shape, weights=None, iou_thr=iou_threshold)\n",
    "    else:\n",
    "        # Boxes, Classes and Scores returned from NMS\n",
    "        n_boxes, n_classes, n_scores = nms_boxes(boxes, classes, scores, iou_threshold, confidence=confidence)\n",
    "\n",
    "    if n_boxes:\n",
    "        boxes = np.concatenate(n_boxes)\n",
    "        classes = np.concatenate(n_classes).astype('int32')\n",
    "        scores = np.concatenate(n_scores)\n",
    "        boxes, classes, scores = filter_boxes(boxes, classes, scores, max_boxes)\n",
    "\n",
    "        return boxes, classes, scores\n",
    "\n",
    "    else:\n",
    "        return [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-harassment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms_boxes(boxes, classes, scores, iou_threshold, confidence=0.1, use_diou=True, is_soft=False, use_exp=False, sigma=0.5):\n",
    "    # boxes: [number, 4]、classes:[number, ]、scores:[number, ]\n",
    "    nboxes, nclasses, nscores = [], [], []\n",
    "    \n",
    "    for c in set(classes):\n",
    "        # 处理一类的所有数据\n",
    "        inds = np.where(classes == c)\n",
    "        b = boxes[inds]  # [len(inds), 4]\n",
    "        c = classes[inds]  # [len(inds), ]\n",
    "        s = scores[inds]  # [len(inds), ]\n",
    "        \n",
    "        # make a data copy to avoid breaking\n",
    "        # during nms operation\n",
    "        b_nms = copy.deepcopy(b)\n",
    "        c_nms = copy.deepcopy(c)\n",
    "        s_nms = copy.deepcopy(s)\n",
    "        \n",
    "        while len(s_nms) > 0:\n",
    "            # 获取这一类中分数最高值，并保存\n",
    "            i = np.argmax(s_nms, axis=-1)\n",
    "            nboxes.append(copy.deepcopy(b_nms[i]))\n",
    "            nclasses.append(copy.deepcopy(c_nms[i]))\n",
    "            nscores.append(copy.deepcopy(s_nms[i]))\n",
    "            \n",
    "            # 交换最大一行和第一行，方便nms\n",
    "            b_nms[[i,0],:] = b_nms[[0,i],:]\n",
    "            c_nms[[i,0]] = c_nms[[0,i]]\n",
    "            s_nms[[i,0]] = s_nms[[0,i]]\n",
    "            \n",
    "            # 选择 box 计算 iou 的方法\n",
    "            if use_diou:\n",
    "                iou = box_diou(b_nms)\n",
    "            else:\n",
    "                iou = box_iou(b_nms)\n",
    "                \n",
    "            # drop the 1st line since it has been record\n",
    "            b_nms = b_nms[1:]\n",
    "            c_nms = c_nms[1:]\n",
    "            s_nms = s_nms[1:]\n",
    "            \n",
    "            # 选择使用软 nms 还是硬 nms\n",
    "            if is_soft:\n",
    "                # Soft-NMS\n",
    "                if use_exp:\n",
    "                    # score refresh formula:\n",
    "                    # score = score * exp(-(iou^2)/sigma)\n",
    "                    s_nms = s_nms * np.exp(-(iou * iou) / sigma)\n",
    "                else:\n",
    "                    # score refresh formula:\n",
    "                    # score = score * (1 - iou) if iou > threshold\n",
    "                    depress_mask = np.where(iou > iou_threshold)[0]\n",
    "                    s_nms[depress_mask] = s_nms[depress_mask]*(1-iou[depress_mask])\n",
    "                keep_mask = np.where(s_nms >= confidence)[0]\n",
    "            else:\n",
    "                # normal Hard-NMS\n",
    "                keep_mask = np.where(iou <= iou_threshold)[0]\n",
    "            \n",
    "            # 在剩下的数组中继续上面步骤\n",
    "            b_nms = b_nms[keep_mask]\n",
    "            c_nms = c_nms[keep_mask]\n",
    "            s_nms = s_nms[keep_mask]\n",
    "            \n",
    "    # reformat result for output\n",
    "    nboxes = [np.array(nboxes)]\n",
    "    bclasses = [np.array(nclasses)]\n",
    "    nscores = [np.sarray(nscores)]\n",
    "    \n",
    "    return nboxes, nclasses, nscores\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-chance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-planner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-danger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-championship",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "square-entry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_nms(yolo_feats, yolo_max_boxes, yolo_iou_threshold, yolo_score_threshold):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    bbox_per_stage, objectness_per_stage, class_probs_stage = [], [], []\n",
    "    \n",
    "    for stage_feats in yolo_feats:\n",
    "        # boxes总数 = grid_x * grid_y * num_anchors \n",
    "        num_boxes = (stage_feats[0].shape[1] * stage_feats[0].shape[2] * stage_feats[0].shape[3])  \n",
    "        \n",
    "        bbox_per_stage.append(\n",
    "            tf.reshape(\n",
    "                stage_feats[0],\n",
    "                (tf.shape(stage_feats[0])[0], num_boxes, stage_feats[0].shape[-1]),\n",
    "            )\n",
    "        )  # [None,num_boxes,4]\n",
    "        \n",
    "        objectness_per_stage.append(\n",
    "            tf.reshape(\n",
    "                stage_feats[1],\n",
    "                (tf.shape(stage_feats[1])[0], num_boxes, stage_feats[1].shape[-1]),\n",
    "            )\n",
    "        )  # [None,num_boxes,1]\n",
    "        \n",
    "        class_probs_per_stage.append(\n",
    "            tf.reshape(\n",
    "                stage_feats[2],\n",
    "                (tf.shape(stage_feats[2])[0], num_boxes, stage_feats[2].shape[-1]),\n",
    "            )\n",
    "        )  # [None,num_boxes,num_classes]\n",
    "        \n",
    "    bbox = tf.concat(bbox_per_stage, axis=1)\n",
    "    objectness = tf.concat(objectness_per_stage, axis=1)\n",
    "    class_probs = tf.concat(class_probs_per_stage, axis=1)\n",
    "\n",
    "    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "        boxes=tf.expand_dims(bbox, axis=2),\n",
    "        scores=objectness * class_probs,\n",
    "        max_output_size_per_class=yolo_max_boxes,\n",
    "        max_total_size=yolo_max_boxes,\n",
    "        iou_threshold=yolo_iou_threshold,\n",
    "        score_threshold=yolo_score_threshold,\n",
    "    )\n",
    "\n",
    "    return [boxes, scores, classes, valid_detections]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "progressive-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolov4_head(\n",
    "    input_shapes,\n",
    "    anchors,\n",
    "    num_classes,\n",
    "    training,\n",
    "    yolo_max_boxes,\n",
    "    yolo_iou_threshold,\n",
    "    yolo_score_threshold,\n",
    "):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        input_shapes (List[Tuple[int]]): List of 3 tuples, which are the output shapes of the neck.\n",
    "            None dimensions are ignored.\n",
    "            For CSPDarknet53+YOLOv4_neck, those are: [ (52, 52, 128), (26, 26, 256), (13, 13, 512)] for a (416,\n",
    "            416) input.\n",
    "        anchors (List[numpy.array[int, 2]]): List of 3 numpy arrays containing the anchor sizes used for each stage.\n",
    "            The first and second columns of the numpy arrays respectively contain the anchors width and height.\n",
    "        num_classes (int): Number of classes.\n",
    "        training (boolean): If False, will output boxes computed through YOLO regression and NMS, and YOLO features\n",
    "            otherwise. Set it True for training, and False for inferences.\n",
    "        yolo_max_boxes (int): Maximum number of boxes predicted on each image (across all anchors/stages)\n",
    "        yolo_iou_threshold (float between 0. and 1.): IOU threshold defining whether close boxes will be merged\n",
    "            during non max regression.\n",
    "        yolo_score_threshold (float between 0. and 1.): Boxes with score lower than this threshold will be filtered\n",
    "            out during non max regression.\n",
    "    Returns:\n",
    "        tf.keras.Model: Head model\n",
    "    \"\"\"\n",
    "    input_1 = tf.keras.Input(shape=filter(None, input_shapes[0]))  # 52* 52* 128\n",
    "    input_2 = tf.keras.Input(shape=filter(None, input_shapes[1]))  # 26* 26* 256\n",
    "    input_3 = tf.keras.Input(shape=filter(None, input_shapes[2]))  # 13* 13* 512\n",
    "    \n",
    "    # p3 输出\n",
    "    P3_out = darknet_CBL(256, (3,3))(input_1)\n",
    "    output_1 = DarknetConv2D(len(anchors[0])*(num_classes+5),(1,1))(P3_out)  # len(anchor[0]) = 3, num_classes=80，整个网络输入为(416, 416)的情况下，此时的输出为13* 13* (3*85)\n",
    "    output_1 = Reshape( (P3.shape[1], P3.shape[2], len(anchors[0]), num_classes + 5))(output_1)  # 13* 13* 3* 85\n",
    "    \n",
    "    # p3 下采样与 p4 实现 FPN，获得 concatenate 后的 p4\n",
    "    P3_downsample = darknet_CBL(256, (3,3), strides=(2,2))(input_1)\n",
    "    P4 = Concatenate()([P3_downsample, input_2])\n",
    "    # p4 CBL*5\n",
    "    P4 = make_five_convs(P4,256)\n",
    "    # p4 输出\n",
    "    P4_out = darknet_CBL(512, (3,3))(P4)\n",
    "    output_2 = DarknetConv2D(len(anchors[1])*(num_classes+5), (1,1))(P4_out)\n",
    "    output_2 = Reshape( (P4.shape[1], P4.shape[2], len(anchors[1]), num_classes + 5))(output_2)  # 26* 26* 3* 85\n",
    "    \n",
    "    \n",
    "    # p4 下采样与 p5 实现 FPN，获得 concatenate 后的 p5\n",
    "    P4_downsample = darknet_CBL(512, (3,3), strides=(2,2))(P4)\n",
    "    P5 = Concatenate()([P4_downsample, input_3])\n",
    "    # p5 CBL*5\n",
    "    P5 = make_five_convs(P5,512)\n",
    "    # p5输出\n",
    "    P5_out = darknet_CBL(1024, (3,3))(P5)\n",
    "    output_3 = DarknetConv2D(len(anchors[2])*(num_classes+5), (1,1))(P5_out)\n",
    "    output_3 = Reshape( (P5.shape[1], P5.shape[2], len(anchors[2]), num_classes + 5))(output_3)  # 52* 52* 3* 85\n",
    "\n",
    "    # 三张特征图 output_1(13* 13* 3* 85)、output_2(26* 26* 3* 85)、output_3(52* 52* 3* 85）从上往下\n",
    "    # 是整个 yolo 输出的检测结果\n",
    "    # 检测框位置（4维）、检测置信度（1维）、类别（80维）都在其中，加起来正好是85维。\n",
    "    # 特征图其他维度N × N × 3，N × N代表了检测框的参考位置信息，3是3个不同尺度的先验框\n",
    "    # 训练阶段则直接返回特征图结果，推理阶段则解码检测信息\n",
    "    \n",
    "    # 训练阶段\n",
    "    if training:\n",
    "        return tf.keras.Model(\n",
    "            [input_1, input_2, input_3],\n",
    "            [output_1, output_2, output_3],\n",
    "            name=\"YOLOv3_head\",\n",
    "        )\n",
    "    \n",
    "    # 推理阶段\n",
    "    # 解码三张特征图的信息\n",
    "    predictions_1 = tf.keras.layers.Lambda(\n",
    "        lambda x_input: yolov3_boxes_regression(x_input, anchors[0]),\n",
    "        name=\"yolov3_boxes_regression_small_scale\",\n",
    "    )(output_1)\n",
    "    predictions_2 = tf.keras.layers.Lambda(\n",
    "        lambda x_input: yolov3_boxes_regression(x_input, anchors[1]),\n",
    "        name=\"yolov3_boxes_regression_medium_scale\",\n",
    "    )(output_2)\n",
    "    predictions_3 = tf.keras.layers.Lambda(\n",
    "        lambda x_input: yolov3_boxes_regression(x_input, anchors[2]),\n",
    "        name=\"yolov3_boxes_regression_large_scale\",\n",
    "    )(output_3)\n",
    "    \n",
    "    # nms处理\n",
    "    output = tf.keras.layers.Lambda(\n",
    "        lambda x_input: yolo_nms(\n",
    "            x_input,\n",
    "            yolo_max_boxes=yolo_max_boxes,\n",
    "            yolo_iou_threshold=yolo_iou_threshold,\n",
    "            yolo_score_threshold=yolo_score_threshold,\n",
    "        ),\n",
    "        name=\"yolov4_nms\",\n",
    "    )([predictions_1, predictions_2, predictions_3])\n",
    "\n",
    "    return tf.keras.Model([input_1, input_2, input_3], output, name=\"YOLOv3_head\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-server",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
