{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hollow-uganda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from a_csp_darknet53.ipynb\n",
      "importing Jupyter notebook from z_layers.ipynb\n"
     ]
    }
   ],
   "source": [
    "import Ipynb_importer\n",
    "from a_csp_darknet53  import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "crazy-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import (Add, BatchNormalization, Concatenate,\n",
    "                                     Conv2D, LeakyReLU, MaxPooling2D,Reshape,\n",
    "                                     UpSampling2D, ZeroPadding2D)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-airport",
   "metadata": {},
   "source": [
    "## 1、定义 yolo neck\n",
    "<img src=\"https://pic3.zhimg.com/80/v2-5251e9c0784871a37c693d53f7d57f92_1440w.jpg\" alt=\"img\" style=\"zoom:30%;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "comparable-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolov4_neck(feature_maps, feature_channel_nums, num_anchors, num_classes):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    f1, f2, f3 = feature_maps # (f1:19x19|f2:38*38|f3:76*76 for input input)\n",
    "    f1_channel_num, f2_channel_num, f3_channel_num = feature_channel_nums\n",
    "    \n",
    "    # feature map 1(19x19 for 608 input)\n",
    "    x1 = make_three_darknet_CBL(f1, f1_channel_num//2)\n",
    "    x1 = Spp(x1)\n",
    "    x1 = make_three_darknet_CBL(x1, f1_channel_num//2)\n",
    "    x1_upsample = compose(\n",
    "        Darknet_CBL(f2_channel_num//2,(1,1)),\n",
    "        UpSampling2D(2))(x1)\n",
    "    \n",
    "    x2 = Darknet_CBL(f2_channel_num//2,(1,1))(f2)\n",
    "    x2 = Concatenate()([x2, x1_upsample])\n",
    "    \n",
    "    # After concatenate: feature map 2(38x38 for 608 input)\n",
    "    x2 = make_five_darknet_CBL(x2, f2_channel_num//2)\n",
    "    x2_upsample = compose(\n",
    "        Darknet_CBL(f3_channel_num//2,(1,1)),\n",
    "        UpSampling2D(2))(x1)\n",
    "    \n",
    "    x3 = Darknet_CBL(f3_channel_num//2,(1,1))(f3)\n",
    "    x3 = Concatenate()([x3, x2_upsample])\n",
    "    \n",
    "    # After concatenate: feature map 3(76x76 for 608 input)\n",
    "    x3 = make_five_darknet_CBL(x3, f3_channel_num//2)\n",
    "    \n",
    "    # ----------------------------------------------------------------------------\n",
    "    \n",
    "    # output (76x76 for 608 input)\n",
    "    y3 = compose(\n",
    "        Darknet_CBL(f3_channel_num//2,(1,1)),\n",
    "        Darknet_Conv2D(num_anchors*(num_classes+5), (1,1), name='predict_conv_3'))(x3)\n",
    "    \n",
    "    # downsample fpn merge for feature map 3 & 2\n",
    "    x3_downsample = compose(\n",
    "        ZeroPadding2D(((1,0),(1,0))),\n",
    "        Darknet_CBL(f2_channel_num//2, (3,3), strides=(2,2)))(x3)\n",
    "    x2 = Concatenate()([x3_downsample, x2])\n",
    "    x2 = make_five_darknet_CBL(x2, f2_channel_num//2)\n",
    "    \n",
    "    # output (38x38 for 608 input)\n",
    "    y2 = compose(\n",
    "        Darknet_CBL(f2_channel_num//2,(1,1)),\n",
    "        Darknet_Conv2D(num_anchors*(num_classes+5), (1,1), name='predict_conv_2'))(x2)\n",
    "    \n",
    "    # downsample fpn merge for feature map 2 & 1\n",
    "    x2_downsample = compose(\n",
    "            ZeroPadding2D(((1,0),(1,0))),\n",
    "            Darknet_CBL(f1_channel_num//2, (3,3), strides=(2,2)))(x2)\n",
    "    x1 = Concatenate()([x2_downsample, x1])\n",
    "    x1 = make_yolo_head(x1, f1_channel_num//2)\n",
    "    \n",
    "    # output (19x19 for 608 input)\n",
    "    y1 = compose(\n",
    "        Darknet_CBL(f1_channel_num, (3,3)),\n",
    "        Darknet_Conv2D(num_anchors*(num_classes+5), (1,1), name='predict_conv_1'))(x1)\n",
    "    \n",
    "    return y1, y2, y3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-temple",
   "metadata": {},
   "source": [
    "## 3、定义 yolo4_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "younger-kitty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo4_body(inputs, num_anchors, num_classes, weights_path=None):\n",
    "    \"\"\"Create YOLOv4 model CNN body in keras\"\"\"\n",
    "    darknet = Model(inputs, csp_darknet53_body(inputs))\n",
    "    print('backbone layers number: {}'.format(len(darknet.layers)))\n",
    "    if weights_path is not None:\n",
    "        darknet.load_weights(weights_path, by_name=True)\n",
    "        print('Load weights {} .'.format(weights_path))\n",
    "        \n",
    "    f1 = darknet.output\n",
    "    f2 = darknet.layers[204].output\n",
    "    f3 = darknet.layers[131].output\n",
    "    \n",
    "    y1, y2, y3 = yolov4_neck((f1, f2, f3), (1024, 512, 256), num_anchors, num_classes)\n",
    "    \n",
    "    return Model(inputs, [y1, y2, y3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
