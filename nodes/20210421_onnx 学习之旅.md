# 20210421_onnx 学习之旅

## 1、ONNX opset_version

ONNX 原来有版本啊

正常情况下，支持 opset-9

## 2、tensorflow-onnx 仓库

> https://github.com/onnx/tensorflow-onnx

## 3、ONNX 相关资料

> https://zhuanlan.zhihu.com/p/346511883

### 3.1 什么是 ONNX？

开放神经网络交换 （Open Neural Network Exchange）简称 ONNX 是微软和 Facebook 提出用来表示深度学习模型的开放合适。

所谓开放就是 ONNX 定义了一组和环境平台无关的标准格式，来增强各种 AI 模型的可交互性。

换句话说，无论你使用何种训练框架训练模型（Tensoflow/Pytorch...），在训练完毕后你可以将这些框架的模型统一转换成 ONNX 这种统一的格式进程存储。注意，ONNX 文件中不仅仅存储了**神经网络模型的权重**，同时也存储了**模型的结构信息**以及**网络中每一层的输入输出**和一些其他的辅助信息。

> 可以使用 netron 查看网络结构

在获取到 ONNX 模型之后，模型部署人员可以将这个模型部署到兼容 ONNX 的运行环境中。这里一般还会设计到额外的模型转换工作。典型的比如在Android端利用NCNN部署ONNX格式模型，那么就需要将ONNX利用NCNN的转换工具转换到NCNN所支持的`bin`和`param`格式。

### 3.2 ProtoBuf 简介

在分析 ONNX 组织格式前我们需要了解 Protobuf。

ONNX 使用的是 Protobuf 这个序列化数据结构去存储神经网络的权重信息。Caffe 或者 Caffe2 的模型存储数据结构协议是 Protobuf。

Protobuf 是一种轻便高效的结构化数据存储格式，可以用于结构化数据串行化，或者说序列化。它很适合做数据存储或数据交换格式。可用于通讯协议、数据存储等领域的语言无关、平台无关、可扩展的序列化结构数据格式。目前提供了 C++、Java、Python 三种语言的 API（摘自官方介绍）。

Protobuf协议是一个以`*.proto`后缀文件为基础的，这个文件描述了用户自定义的数据结构。如果需要了解更多细节请参考0x7节的资料3，这里只是想表达ONNX是基于Protobuf来做数据存储和传输，那么自然`onnx.proto`就是ONNX格式文件了，接下来我们就分析一下ONNX格式。

### 3.3 ONNX 格式分析

这一节我们来分析一下ONNX的组织格式，上面提到ONNX中最核心的部分就是`onnx.proto`（`https://github.com/onnx/onnx/blob/master/onnx/onnx.proto`）这个文件了，它定义了ONNX这个数据协议的规则和一些其它信息。现在是2021年1月，这个文件有700多行，我们没有必要把这个文件里面的每一行都贴出来，我们只要搞清楚里面的核心部分即可。在这个文件里面以`message`关键字开头的对象是我们需要关心的。我们列一下最核心的几个对象并解释一下它们之间的关系。

- `ModelProto`
- `GraphProto`
- `NodeProto`
- `ValueInfProto`
- `TensorProto`
- `AttributeProto`

当我们加载一个 ONNX 之后，我们获得是一个 `ModelProto`，，它包含了一些版本信息，生产者信息和一个`GraphProto`。

在`GraphProto`里面又包含了四个`repeated`数组，它们分别是`node`(`NodeProto`类型)，`input`(`ValueInfoProto`类型)，`output`(`ValueInfoProto`类型)和**`initializer`(`TensorProto`类型)**。

其中，`node`中存放了模型中所有的计算节点，`input`存放了模型的输入节点，`output`存放了模型中所有的输出节点，**`initializer`存放了模型的所有权重参数**。

我们想完整的表达一个神经网络，不仅仅要知道网络的各个节点信息，还要知道它们的拓扑关系。这个拓扑关系在ONNX中是如何表示的呢？ONNX的每个计算节点都会有`input`和`output`两个数组，这两个数组是string类型，通过`input`和`output`的指向关系，我们就可以利用上述信息快速构建出一个深度学习模型的拓扑图。

> 这里要注意一下，`GraphProto`中的`input`数组不仅包含我们一般理解中的图片输入的那个节点，还包含了模型中所有的权重。例如，`Conv`层里面的`W`权重实体是保存在`initializer`中的，那么相应的会有一个同名的输入在`input`中，其背后的逻辑应该是把权重也看成模型的输入，并通过`initializer`中的权重实体来对这个输入做初始化，即一个赋值的过程。

最后，**每个计算节点中还包含了一个`AttributeProto`数组**，用来描述该节点的属性，比如`Conv`节点或者说卷积层的属性包含`group`，`pad`，`strides`等等，每一个计算节点的属性，输入输出信息都详细记录在`https://github.com/onnx/onnx/blob/master/docs/Operators.md`。

### 3.4 onnx.helper

现在我们知道 ONNX 是把一个网络的每一层或者说一个算子当作节点 `node`，使用这些 `node`去构建一个 `Graph`，即一个网络。最后将`Graph`和其它的生产者信息，版本信息等合并在一起生成一个`Model`，也即是最终的ONNX模型文件。

在构建ONNX模型的时候，`https://github.com/onnx/onnx/blob/master/onnx/helper.py`这个文件非常重要，我们可以利用它提供的`make_node`，`make_graph`，`make_tensor`等等接口完成一个ONNX模型的构建，一个示例如下：

```python
import onnx
from onnx import helper
from onnx import AttributeProto, TensorProto, GraphProto

# The protobuf definition can be found here:
# https://github.com/onnx/onnx/blob/master/onnx/onnx.proto

# Create one input (ValueInfoProto)
X = helper.make_tensor_value('X', TensorProto.FLOAT, [3,2])
pads = helper.make_tensor_value_info('pads', TensorProto.FLOAT, [1, 4])
value = helper.make_tensor_value_info('value', AttributeProto.FLOAT, [1])

# Create one output (ValueInfoProto)
Y = helper.make_tensor_value_info('Y', TensorProto.FLOAT, [3, 4])

# Create a node (NodeProto) - This is based on Pad-11
node_def = helper.make_node(
	'Pad', # node name
    ['X', 'pads', 'value'],  # inputs
    ['Y'],  # outputs
    mode='constant',  # attributes
)

# Create the graph (GraphProto)
graph_def = helper.make_graph(
    [node_def],
    'test-model',
    [X, pads, value],
    [Y],
)

# Create the model (ModelProto)
model_def = helper.make_model(graph_def, producer_name='onnx-example')

print('The model is:\n{}'.format(model_def))
onnx.checker.check_model(model_def)
print('The model is checked!')
```

这个官方示例为我们演示了如何使用`onnx.helper`的`make_tensor`，`make_tensor_value_info`，`make_attribute`，`make_node`，`make_graph`，`make_node`等方法来完整构建了一个ONNX模型。需要注意的是在上面的例子中，输入数据是一个一维Tensor，初始维度为`[2]`，这也是为什么经过维度为`[1,4]`的Pad操作之后获得的输出Tensor维度为`[3,4]`。另外由于Pad操作是没有带任何权重信息的，所以当你打印ONNX模型时，`ModelProto`的`GraphProto`是没有`initializer`这个属性的。

### 3.5 onnx-simplifier

使用ONNX进行模型部署经常碰到一些因为版本兼容性，或者各种框架OP没有对齐等原因导致的各种BUG。这里以一个经典的Pytorch转ONNX的reshape问题为例子，来尝试讲解一下大老师的onnx-simplifier是怎么处理的.

当我们



